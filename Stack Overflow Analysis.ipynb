{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import tempfile\n",
    "import shutil\n",
    "import subprocess\n",
    "import shlex\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas\n",
    "import xml.etree.cElementTree as etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Exchange Analysis\n",
    "\n",
    "# Introduction\n",
    "\n",
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Data\n",
    "\n",
    "## Downloading the data\n",
    "Our first step is to download the [data dumps](https://archive.org/details/stackexchange). Currently, the Stack Exchange Network hosts their data dumps through the [Internet Archive](https://archive.org/). Dump files are provided for each network (aside from StackOverflow for which there are multiple files) and are compressed using the 7z archive format. Thus, the code below to download and uncompress the data archive requires having the `7z` binary, acquirable through `apt-get`, `brew` and other package managers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_network_data(network, path=''):\n",
    "    '''downloads StackExchange network data from archive.org'''\n",
    "\n",
    "    # download archive\n",
    "    url = 'https://archive.org/download/stackexchange/%s.stackexchange.com.7z' % network\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile('wb') as f:\n",
    "        # copy 7z archive into the filesystem\n",
    "        response.raw.decode_content = False\n",
    "        f.write(response.content)\n",
    "        f.flush()\n",
    "        \n",
    "        # create a folder to store the XML data\n",
    "        path = os.path.join(path, network)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        # there are few Python 7z compatible libraries and they don't\n",
    "        # work correctly with these archives (overwrite switch enabled)\n",
    "        args = shlex.split('7z x %s -aoa \"-o%s\"' % (f.name, path))\n",
    "        return subprocess.check_call(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = 'ai'\n",
    "get_network_data(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we've downloaded the archive, it's time to load the XML data within it into a database that can be easily queried when we're building our features. The [README](https://ia800500.us.archive.org/22/items/stackexchange/readme.txt) provided with the data dump describes the schema of each table and below we provide a visualization of these tables as well as the types of each field once we load them into our database. This visualization was created with the use of [WWW SQL Designer](https://ondras.zarovi.cz/sql/demo/). We note that the `posts` table covers both answers and questions and that `badges` are awards of a sort that users recieve for achieving certain milestones. While we deemphasize some of these tables throughout the feature engineering process, we nevertheless mention them here and process them for the sake of completeness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Database schema](schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a SQLite database conforming to the above schema (duplicated below as a Python dictionary). Inspiration is taken from [zhangqiaorjc/sedumpy](https://github.com/zhangqiaorjc/sedumpy/blob/master/makedb.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'badges': {\n",
    "        'Id': 'INTEGER PRIMARY KEY',\n",
    "        'UserId': 'INTEGER',\n",
    "        'Name': 'VARCHAR(50)',\n",
    "        'Date': 'DATETIME',\n",
    "        'Class': 'INTEGER',\n",
    "        'TagBased': 'VARCHAR(8)',\n",
    "    },\n",
    "    'comments': {\n",
    "        'Id': 'INTEGER PRIMARY KEY',\n",
    "        'PostId': 'INTEGER',\n",
    "        'Score': 'INTEGER',\n",
    "        'Text': 'TEXT',\n",
    "        'CreationDate': 'DATETIME',\n",
    "        'UserId': 'INTEGER',\n",
    "    },\n",
    "    'posts': {\n",
    "        'Id': 'INTEGER PRIMARY KEY',\n",
    "        'PostTypeId': 'INTEGER', # 1: Question, 2: Answer\n",
    "        'ParentId': 'INTEGER', # present only if PostTypeId = 2\n",
    "        'AcceptedAnswerId': 'INTEGER', # present only if PostTypeId = 1\n",
    "        'CreationDate': 'DATETIME',\n",
    "        'Score': 'INTEGER',\n",
    "        'ViewCount': 'INTEGER',\n",
    "        'Body': 'TEXT',\n",
    "        'OwnerUserId': 'INTEGER', # present only if user has not been deleted\n",
    "        'LastEditorUserId': 'INTEGER',\n",
    "        'LastEditDate': 'DATETIME',\n",
    "        'LastActivityDate': 'DATETIME',\n",
    "        'Title': 'VARCHAT(256)',\n",
    "        'Tags': 'VARCHAT(256)',\n",
    "        'AnswerCount': 'INTEGER',\n",
    "        'CommentCount': 'INTEGER',\n",
    "        'FavoriteCount': 'INTEGER',\n",
    "        'ClosedDate': 'DATETIME'\n",
    "    },\n",
    "    'votes': {\n",
    "        'Id': 'INTEGER PRIMARY KEY',\n",
    "        'PostId': 'INTEGER',\n",
    "        'UserId': 'INTEGER',\n",
    "        'VoteTypeId': 'INTEGER',\n",
    "            # 1: AcceptedByOriginator\n",
    "            # 2: UpMod\n",
    "            # 3: DownMod\n",
    "            # 4: Offensive\n",
    "            # 5: Favorite\n",
    "            # 6: Close\n",
    "            # 7: Reopen\n",
    "            # 8: BountyStart\n",
    "            # 9: BountyClose\n",
    "            # 10: Deletion\n",
    "            # 11: Undeletion\n",
    "            # 12: Spam\n",
    "            # 13: InformModerator\n",
    "        'CreationDate': 'DATETIME',\n",
    "    },\n",
    "    'post_history': {\n",
    "        'Id': 'INTEGER PRIMARY KEY',\n",
    "        'PostHistoryTypeId': 'INTEGER',\n",
    "        'PostId': 'INTEGER',\n",
    "        'RevisionGUID': 'VARCHAR(36)',\n",
    "        'CreationDate': 'DATETIME',\n",
    "        'UserId': 'INTEGER',\n",
    "        'Comment': 'TEXT',\n",
    "        'Text': 'TEXT'\n",
    "    },\n",
    "    'post_links': {\n",
    "        'Id': 'INTEGER PRIMARY KEY',\n",
    "        'CreationDate': 'DATETIME',\n",
    "        'PostId': 'INTEGER',\n",
    "        'RelatedPostId': 'INTEGER',\n",
    "        'LinkTypeId': 'INTEGER'\n",
    "    },\n",
    "    'users': {\n",
    "        'Id': 'INTEGER PRIMARY KEY',\n",
    "        'Reputation': 'INTEGER',\n",
    "        'CreationDate': 'DATETIME',\n",
    "        'DisplayName': 'VARCHAR(50)',\n",
    "        'LastAccessDate': 'DATETIME',\n",
    "        'WebsiteUrl': 'VARCHAR(256)',\n",
    "        'Location': 'VARCHAR(256)',\n",
    "        'Age': 'INTEGER',\n",
    "        'AboutMe': 'TEXT',\n",
    "        'Views': 'INTEGER',\n",
    "        'UpVotes': 'INTEGER',\n",
    "        'DownVotes': 'INTEGER',\n",
    "        'AccountId': 'INTEGER',\n",
    "        'ProfileImageUrl': 'VARCHAR(256)'\n",
    "    },\n",
    "    'tags': {\n",
    "        'Id': 'INTEGER PRIMARY KEY',\n",
    "        'TagName': 'TEXT',\n",
    "        'Count': 'INTEGER',\n",
    "        'ExcerptPostId': 'INTEGER',\n",
    "        'WikiPostId': 'INTEGER'\n",
    "    }\n",
    "}\n",
    "\n",
    "# define a f\n",
    "def create_table(c, name, constraints=[]):\n",
    "    '''Creates a single table under the schema given its name and constraints'''\n",
    "    fields = list(map(lambda x: '%s %s' % x, schema[name].items()))\n",
    "    c.execute(\n",
    "        'CREATE TABLE %s (%s)' % (\n",
    "            name,\n",
    "            ', '.join(fields + constraints)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def create_database(network, path='', database=None):\n",
    "    '''Creates a database containing all the Stack Exchange network data'''\n",
    "    \n",
    "    # choose a name for the database\n",
    "    if not database:\n",
    "        database = '%s.db' % network\n",
    "    database = os.path.join(path, database)\n",
    "    \n",
    "    conn = sqlite3.connect(database)\n",
    "    \n",
    "    c = conn.cursor()\n",
    "    \n",
    "    create_table(c, 'users')\n",
    "    create_table(c, 'badges', ['FOREIGN KEY(UserId) REFERENCES users(Id)'])\n",
    "    create_table(c, 'posts', [\n",
    "        'FOREIGN KEY(AcceptedAnswerId) REFERENCES posts(Id)',\n",
    "        'FOREIGN KEY(ParentId) REFERENCES posts(Id)',\n",
    "        'FOREIGN KEY(OwnerUserId) REFERENCES users(Id)'\n",
    "    ])\n",
    "    create_table(c, 'votes', [\n",
    "        'FOREIGN KEY(PostId) REFERENCES posts(Id)',\n",
    "        'FOREIGN KEY(UserId) REFERENCES users(Id)'\n",
    "    ])\n",
    "    create_table(c, 'tags', [\n",
    "        'FOREIGN KEY(WikiPostId) REFERENCES posts(Id)',\n",
    "        'FOREIGN KEY(ExcerptPostId) REFERENCES posts(Id)'\n",
    "    ])\n",
    "    create_table(c, 'comments', [\n",
    "        'FOREIGN KEY(PostId) REFERENCES posts(Id)',\n",
    "        'FOREIGN KEY(UserId) REFERENCES users(Id)'\n",
    "    ])\n",
    "    create_table(c, 'post_history', [\n",
    "        'FOREIGN KEY(PostId) REFERENCES posts(Id)',\n",
    "        'FOREIGN KEY(UserId) REFERENCES users(Id)'\n",
    "    ])\n",
    "    create_table(c, 'post_links', [\n",
    "        'FOREIGN KEY(PostId) REFERENCES posts(Id)',\n",
    "    ])\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    return (conn, database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn, database = create_database(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a series of indices to make our later queries faster,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_indices(conn):\n",
    "    '''creates indices on the tables to speed up later queries'''\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute('CREATE INDEX badges_idx_1 ON badges(UserId);')\n",
    "\n",
    "    c.execute('CREATE INDEX comments_idx_1 ON comments(PostId);')\n",
    "    c.execute('CREATE INDEX comments_idx_2 ON comments(UserId);')\n",
    "\n",
    "    c.execute('CREATE INDEX post_history_idx_1 ON post_history(PostId);')\n",
    "    c.execute('CREATE INDEX post_history_idx_2 ON post_history(UserId);')\n",
    "\n",
    "    c.execute('CREATE INDEX posts_idx_1 ON posts(AcceptedAnswerId);')\n",
    "    c.execute('CREATE INDEX posts_idx_2 ON posts(ParentId);')\n",
    "    c.execute('CREATE INDEX posts_idx_3 ON posts(OwnerUserId);')\n",
    "    c.execute('CREATE INDEX posts_idx_4 ON posts(LastEditorUserId);')\n",
    "\n",
    "    c.execute('CREATE INDEX votes_idx_1 ON votes(PostId);')\n",
    "    \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_indices(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we populate the database, one XML file at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xml_file_name(path, table):\n",
    "    '''returns the path to the XML file corresponding to a particular table'''\n",
    "    return os.path.join(path, ''.join(map(str.capitalize, table.split('_'))) + '.xml')\n",
    "\n",
    "def populate_data(conn, path):\n",
    "    '''populates all the network data given a path to a folder containing the XML dump files'''\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # iterate over each table\n",
    "    for table in ['users', 'badges', 'posts', 'votes', 'tags', 'comments', 'post_history', 'post_links']:\n",
    "        tree = etree.iterparse(xml_file_name(path, table))\n",
    "        for _, record in tree:\n",
    "            if record.attrib.values():\n",
    "                query = 'INSERT INTO %s (%s) VALUES (%s)' % (\n",
    "                    table, \n",
    "                    ', '.join(record.attrib.keys()),\n",
    "                    ('?, ' * len(record.attrib.keys()))[:-2]\n",
    "                )\n",
    "                c.execute(query, record.attrib.values())\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "populate_data(conn, network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's do a little sanity checking to ensure that we've correctly populated the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def santity_check(conn, path):\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    entries = pandas.DataFrame(columns=['table', 'xml_entries', 'db_entries'])\n",
    "    \n",
    "    for table in schema.keys():\n",
    "        tree = etree.iterparse(xml_file_name(path, table))\n",
    "        xml_count = len(list(tree))\n",
    "        db_count = c.execute('SELECT COUNT(*) FROM %s' % table).fetchone()[0]\n",
    "        entries = entries.append([{'table': table, 'xml_entries': xml_count, 'db_entries': db_count}])\n",
    "    \n",
    "    entries['difference'] = (entries['xml_entries'] - entries['db_entries']).map(abs)\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "santity_check(conn, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
